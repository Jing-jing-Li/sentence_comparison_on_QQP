{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bde4200",
   "metadata": {},
   "source": [
    "### SBERT model training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae5c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import InputExample, SentenceTransformer, models, losses, evaluation, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from data_processing import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363e8e4",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6fc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test1, x_test2, x_test3, x_test4, x_test5, y_train, y_test1, y_test2, y_test3, y_test4, y_test5 = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d832b783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of training set is 20214\n",
      "the length of each testing set is 76815\n"
     ]
    }
   ],
   "source": [
    "print('the length of training set is',len(x_train))\n",
    "print('the length of each testing set is',len(x_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a74894c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the training data\n",
    "y1 = sum(float(i) for i in y_train)\n",
    "y0 = len(x_train)-y1\n",
    "plt.bar([0,1],[y0,y1])\n",
    "plt.title('distribution of question pairs in training data')\n",
    "plt.xlabel('is_duplicated')\n",
    "plt.ylabel('number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bea65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of all the data\n",
    "y1_all = sum(float(i) for i in y_train)+sum(float(i) for i in y_test1)+sum(float(i) for i in y_test2)+sum(float(i) for i in y_test3)+sum(float(i) for i in y_test4)+sum(float(i) for i in y_test5)\n",
    "y0_all = len(x_train)+len(x_test1)*5-y1\n",
    "plt.bar([0,1],[y0_all,y1_all])\n",
    "plt.title('distribution of question pairs')\n",
    "plt.xlabel('is_duplicated')\n",
    "plt.ylabel('number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8194fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convinient the training process, change the structure of data\n",
    "def convert_list_data_into_InputExample(x, y):\n",
    "    examples = []\n",
    "    for s, label in zip(x, y):\n",
    "        question1, question2 = s\n",
    "        examples.append(InputExample(texts=[question1, question2], label=float(label)))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc563d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = convert_list_data_into_InputExample(x_train, y_train)\n",
    "test1 = convert_list_data_into_InputExample(x_test1, y_test1)\n",
    "test2 = convert_list_data_into_InputExample(x_test2, y_test2)\n",
    "test3 = convert_list_data_into_InputExample(x_test3, y_test3)\n",
    "test4 = convert_list_data_into_InputExample(x_test4, y_test4)\n",
    "test5 = convert_list_data_into_InputExample(x_test5, y_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fde94e",
   "metadata": {},
   "source": [
    "### train the SBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f4bfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# SBERT model\n",
    "word_embedding_model = models.Transformer('bert-base-uncased', max_seq_length=256)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(),\n",
    "                           out_features=256, activation_function=nn.Tanh())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e77a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, shuffle=True, batch_size=64)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(test1)\n",
    "model_save_path = 'C:/Users/lenovo/Desktop/一起走下去吧/uzh · 学习/2022 Fall/NLP/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1c3f451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc6b924dbfb4889bff9ffc013992e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97514bec36164f89a4911d4888fa84ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 73138176 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1812/4018334997.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(train_objectives=[(train_loader, train_loss)],\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mevaluator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mwarmup_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0msave_best_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[0;32m    719\u001b[0m                         \u001b[0mskip_scheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mscale_before_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m                         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m                         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sentence_transformers\\losses\\CosineSimilarityLoss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sentence_features, labels)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence_embedding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence_feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos_score_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sentence_transformers\\losses\\CosineSimilarityLoss.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence_embedding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence_feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos_score_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token_type_ids'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token_type_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0moutput_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1020\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m         )\n\u001b[1;32m-> 1022\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m   1023\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    609\u001b[0m                 )\n\u001b[0;32m    610\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    612\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[0;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\transformers\\pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\transformers\\activations.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 73138176 bytes."
     ]
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_loader, train_loss)],\n",
    "          epochs=1,\n",
    "          evaluator=evaluator,\n",
    "          warmup_steps=100,\n",
    "          save_best_model=True,\n",
    "          output_path=model_save_path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922629c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
