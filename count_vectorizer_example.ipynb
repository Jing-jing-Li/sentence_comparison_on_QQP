{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### count vectorization example"
      ],
      "metadata": {
        "id": "jInYl59o7067"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR6x0m2p7qrZ",
        "outputId": "c014b8fd-6181-45b3-8390-2b4475155248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.7)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.23.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.97)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (5.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import InputExample, SentenceTransformer, models, losses, evaluation, util\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "AtlbC1uR7wI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = 'What is the most populous state in the USA?'\n",
        "question2 = 'Which state in the United States has the most people?'"
      ],
      "metadata": {
        "id": "tjL889x-8EF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "sample = [question1, question2]"
      ],
      "metadata": {
        "id": "fVB39E3t8OLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(number):\n",
        "    return float(number)"
      ],
      "metadata": {
        "id": "beQnR0Zo9Yun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit = vectorizer.fit_transform(sample).todense()\n",
        "vector1 = fit[0].tolist()[0]\n",
        "vector2 = fit[1].tolist()[0]\n",
        "float_numbers_iterator1 = map(f, vector1)\n",
        "float_numbers_iterator2 = map(f, vector2)\n",
        "vector1 = list(float_numbers_iterator1)\n",
        "vector2 = list(float_numbers_iterator2)\n",
        "words = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "tIUnwVlB8uIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)\n",
        "print(vector1)\n",
        "print(vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev5GEjqZ8-VX",
        "outputId": "9509ccde-f1f5-4246-f336-f33c89802865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['has' 'in' 'is' 'most' 'people' 'populous' 'state' 'states' 'the'\n",
            " 'united' 'usa' 'what' 'which']\n",
            "[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0]\n",
            "[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity1 = util.cos_sim(vector1, vector2)\n",
        "print(similarity1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI_kthjWFQOr",
        "outputId": "21932e3a-80de-498a-a13b-a4d91bdb9174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6093]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract noun\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_noun(s: str):\n",
        "    doc = nlp(s)\n",
        "    if doc[0].pos_ == 'NOUN':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "Wf897kazAJJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector3 = vector1\n",
        "vector4 = vector2\n",
        "for j in range(len(words)):\n",
        "    pro = get_noun(words[j])\n",
        "    if pro==0:\n",
        "        vector3[j]=0.0\n",
        "        vector4[j]=0.0"
      ],
      "metadata": {
        "id": "DK4eX54LAUul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)\n",
        "print(vector3)\n",
        "print(vector4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAFknDTcA3ze",
        "outputId": "40dd52f5-c0ac-4ca8-b324-31ef83a08e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['has' 'in' 'is' 'most' 'people' 'populous' 'state' 'states' 'the'\n",
            " 'united' 'usa' 'what' 'which']\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the similarity\n",
        "similarity2 = util.cos_sim(vector3, vector4)\n",
        "print(similarity2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRTXC_gAA7I9",
        "outputId": "0f5e361c-b236-4e69-d3e6-988492826fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5774]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### influence of typo"
      ],
      "metadata": {
        "id": "g7w7YKVjIi7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question3 = 'What is the most populous stete in the USA?'  # change \"state\" into \"stete\" \n",
        "question4 = 'Which state in the United States has the most people?'\n",
        "vectorizer = CountVectorizer()\n",
        "sample = [question3, question4]"
      ],
      "metadata": {
        "id": "riMBokQzHFFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit = vectorizer.fit_transform(sample).todense()\n",
        "vector1 = fit[0].tolist()[0]\n",
        "vector2 = fit[1].tolist()[0]\n",
        "float_numbers_iterator1 = map(f, vector1)\n",
        "float_numbers_iterator2 = map(f, vector2)\n",
        "vector1 = list(float_numbers_iterator1)\n",
        "vector2 = list(float_numbers_iterator2)\n",
        "words = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "peJmOAXfJ3jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)\n",
        "print(vector1)\n",
        "print(vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxANVBdzJ8HM",
        "outputId": "dcb77177-3c0a-404f-af77-68c4ee06383c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['has' 'in' 'is' 'most' 'people' 'populous' 'state' 'states' 'stete' 'the'\n",
            " 'united' 'usa' 'what' 'which']\n",
            "[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0]\n",
            "[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity3 = util.cos_sim(vector1, vector2)\n",
        "print(similarity3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx4xZfr_KV0U",
        "outputId": "6ce6b4ce-cd5c-4c61-d93b-2606139e29bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5222]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### the performance on abbriviation"
      ],
      "metadata": {
        "id": "uqJms1x0K2eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question5 = 'What is the most populous state in the USA?'\n",
        "question6 = 'Which state in the USA has the most people?' # change \"United State\" to \"USA\"\n",
        "vectorizer = CountVectorizer()\n",
        "sample = [question5, question6]"
      ],
      "metadata": {
        "id": "T0_AclXdKt7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit = vectorizer.fit_transform(sample).todense()\n",
        "vector1 = fit[0].tolist()[0]\n",
        "vector2 = fit[1].tolist()[0]\n",
        "float_numbers_iterator1 = map(f, vector1)\n",
        "float_numbers_iterator2 = map(f, vector2)\n",
        "vector1 = list(float_numbers_iterator1)\n",
        "vector2 = list(float_numbers_iterator2)\n",
        "words = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "HGxZpDEOLNDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)\n",
        "print(vector1)\n",
        "print(vector2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juIOr3VwLPC6",
        "outputId": "3c363df5-1d23-4bcb-afb5-51fee26fc27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['has' 'in' 'is' 'most' 'people' 'populous' 'state' 'the' 'usa' 'what'\n",
            " 'which']\n",
            "[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0]\n",
            "[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity3 = util.cos_sim(vector1, vector2)\n",
        "print(similarity3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riDGYryQLQw4",
        "outputId": "7a5408e6-00d2-43db-f070-72ca57f11716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7273]])\n"
          ]
        }
      ]
    }
  ]
}